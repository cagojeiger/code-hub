# Roadmap v0.2.1: Control Plane + Agent 아키텍처

- **Status**: Idea
- **Created**: 2025-01-12
- **Updated**: 2025-01-13
- **Version**: 0.2.1
- **License**: AGPL-3.0 (이 버전부터 변경)

---

## 1. 핵심 철학

### BYOC (Bring Your Own Cluster) + BYOS (Bring Your Own Storage)

```
Control Plane = 메타데이터/오케스트레이션만 (데이터 비소유)
Agent = 모든 실제 자원 관리 (컨테이너, 볼륨, S3)
```

**Control Plane은 사용자 데이터를 소유하거나 저장하지 않음**

사용자가 자신의 인프라(Docker, K8s, S3/MinIO)를 가져오고, Control Plane은 오케스트레이션만 담당합니다.

---

## 2. 아키텍처

### Control Plane vs Agent 역할 분리

```
┌─────────────────────────────────────────────────────────────┐
│                 Control Plane (Stateful, DB 있음)           │
│                                                             │
│  1. 스케줄링 (Scheduler)                                    │
│     - 클러스터 선택/배치 결정                               │
│                                                             │
│  2. 오케스트레이션 (Reconciler)                             │
│     - 상태 머신 관리 (Phase)                                │
│     - desired vs actual 맞추기                             │
│     - 시작/정지/아카이브 "명령"                             │
│                                                             │
│  3. 자동화 (TTL Manager)                                    │
│     - Idle 감지 → 정지 명령                                │
│     - TTL 만료 → 아카이브 명령                             │
│     - 접속 시 → 시작 명령                                  │
│                                                             │
│  4. 프록시 (Proxy)                                          │
│     - 단일 진입점                                           │
│     - 라우팅                                                │
│                                                             │
│  5. 인증/인가 (Auth)                                        │
│     - 사용자 관리                                           │
│     - 권한 체크                                             │
│                                                             │
│  6. 메타데이터 (DB)                                         │
│     - 상태 저장                                             │
│     - 클러스터/워크스페이스 정보                            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
                           │
                           │ 명령 (HTTP)
                           ▼
┌─────────────────────────────────────────────────────────────┐
│                   Agent (Stateless, DB 없음)                │
│                                                             │
│  실행만:                                                    │
│  - Instance 관리 (컨테이너/Pod 생성/삭제)                  │
│  - Volume 관리 (Docker Volume/PVC)                         │
│  - Job 실행 (archive/restore)                              │
│  - Storage GC (S3 정리)                                    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
                           │
         ┌─────────────────┼─────────────────┐
         ▼                 ▼                 ▼
    ┌────────┐       ┌────────┐        ┌────────┐
    │ Docker │       │  K8s   │        │S3/MinIO│
    │ Engine │       │  API   │        │        │
    └────────┘       └────────┘        └────────┘

    (전부 사용자 소유 인프라)
```

### Control Plane의 가치

| 가치 | 설명 |
|------|------|
| 오케스트레이션 | 여러 클러스터를 하나의 UI로 통합 관리 |
| 자동화 | Idle 감지 → 정지, TTL → 아카이브, 접속 → 시작 |
| 스케줄링 | 클러스터 선택, 리소스 밸런싱 |
| 프록시 | 단일 진입점, NAT 뒤에서도 접근 (SaaS) |
| 상태 관리 | Phase 상태 머신, 장애 복구, 히스토리 |

**Agent만으로는 불가능한 것**:
- Agent는 Stateless (DB 없음)
- 통합 관리, 자동화, 히스토리, 여러 클러스터 연동 불가

---

## 3. Workspace 테이블 변경

### 변경 사항 요약

| 변경 유형 | 컬럼 | 변경 내용 |
|-----------|------|-----------|
| **추가** | `cluster_id` | NOT NULL, FK → clusters |
| **삭제** | `home_store_key` | Agent가 workspace_id로 계산 |
| **삭제** | `instance_backend` | cluster.type으로 대체 |
| **삭제** | `storage_backend` | cluster에서 관리 |

**유지/변경**:
- `archive_op_id`, `op_started_at`: archive S3 경로 생성, GC 보호용 (ARCHIVING/CREATE_EMPTY_ARCHIVE 전용)
- `archive_key`: restore 시 Agent에게 전달 (archive_op_id로 생성된 S3 경로)
- `home_ctx`: restore_marker 저장용 context

---

## 4. DB 스키마 설계

### 테이블 구조

```
┌─────────────────────────────────────────────────────────────────┐
│                        사용자 영역 (기존)                        │
│   users, sessions                                               │
└─────────────────────────────────────────────────────────────────┘
         │
         │ owner_user_id
         ▼
┌─────────────────────────────────────────────────────────────────┐
│                    워크스페이스 영역 (수정)                       │
│   workspaces (id, owner_user_id, cluster_id, name, phase, ...)  │
│              + cluster_id (NOT NULL, FK)                        │
│              - home_store_key (삭제)                            │
│              - instance_backend (삭제)                          │
│              - storage_backend (삭제)                           │
└─────────────────────────────────────────────────────────────────┘
         │
         │ cluster_id (N:1, 직접 참조)
         ▼
┌─────────────────────────────────────────────────────────────────┐
│                      클러스터 영역 (신규)                         │
│   clusters (id, name, type, endpoint, status, ...)              │
│   cluster_members (cluster_id, user_id, role)                   │
└─────────────────────────────────────────────────────────────────┘

※ workspace_placements 테이블 불필요 (workspaces.cluster_id로 직접 참조)
```

### clusters 테이블 (신규)

```
clusters:
  id              UUID PK
  name            VARCHAR(255)
  type            'docker' | 'k8s'
  endpoint        Agent HTTP 주소
  api_key_hash    Agent 인증용
  status          'pending' | 'healthy' | 'unhealthy'
  last_health_at  마지막 헬스체크
  created_at, updated_at
```

### cluster_members 테이블 (신규)

```
cluster_members:
  cluster_id      FK → clusters
  user_id         FK → users
  role            'owner' | 'member'
  granted_by      FK → users (누가 권한 부여)
  created_at
  PK: (cluster_id, user_id)
```

### 권한 규칙

| 행위 | 조건 |
|------|------|
| Cluster 등록 | 로그인한 사용자 |
| Cluster 삭제 | owner만, workspace 없어야 함 (RESTRICT) |
| Grant 부여/회수 | owner만 |
| Workspace 생성 | cluster owner OR member |
| Workspace 접근 | workspace owner만 |

**핵심**: 클러스터 공유 ≠ 워크스페이스 공유

---

## 5. Agent 설계

### Agent 설정 (환경변수)

```
CLUSTER_ID      = "cluster-abc"        # S3 경로 prefix (멀티 클러스터 격리)
RESOURCE_PREFIX = "codehub-"           # 리소스 이름 prefix
S3_ENDPOINT     = "http://minio:9000"  # S3 접속 정보
S3_BUCKET       = "codehub-archives"
S3_ACCESS_KEY   = "..."
S3_SECRET_KEY   = "..."
DOCKER_HOST     = "unix:///var/run/docker.sock"
```

### Agent 내부 규칙 (CP는 모름)

```
volume_name    = f"{RESOURCE_PREFIX}{workspace_id}-home"
container_name = f"{RESOURCE_PREFIX}{workspace_id}"
s3_path        = f"{CLUSTER_ID}/{workspace_id}/{archive_op_id}/home.tar.zst"
```

### API 엔드포인트

```
# Instance
POST   /instances/{workspace_id}/start    → 컨테이너 시작
DELETE /instances/{workspace_id}          → 컨테이너 삭제
GET    /instances/{workspace_id}/status   → 상태 조회
GET    /instances/{workspace_id}/upstream → 프록시 주소

# Volume
POST   /volumes/{workspace_id}            → 볼륨 생성
DELETE /volumes/{workspace_id}            → 볼륨 삭제
GET    /volumes/{workspace_id}/exists     → 존재 확인

# Job (BYOS: S3 경로는 Agent만 알음)
POST   /jobs/archive                      → 아카이브 Job
POST   /jobs/restore                      → 복원 Job

# Storage
POST   /storage/gc                        → S3 GC (보호 목록 전달)

# Health
GET    /health                            → Agent 상태
```

### Instance API 상세

```
POST /instances/{workspace_id}/start
요청: { "image_ref": "ghcr.io/codehub/workspace:latest" }
Agent:
  1. volume_name = f"{prefix}{workspace_id}-home"
  2. container_name = f"{prefix}{workspace_id}"
  3. docker run --name {container_name} -v {volume_name}:/home ...
응답: { "status": "running" }

DELETE /instances/{workspace_id}
Agent:
  1. container_name = f"{prefix}{workspace_id}"
  2. docker stop && docker rm {container_name}
응답: { "status": "deleted" }

GET /instances/{workspace_id}/status
응답: { "exists": true, "running": true, "health": "healthy" }

GET /instances/{workspace_id}/upstream
응답: { "url": "http://172.18.0.5:8080" }  # container IP
```

### Job API 상세

```
POST /jobs/archive
요청: { "workspace_id": "ws-001", "archive_op_id": "op-abc123" }
Agent:
  1. volume_name = f"{prefix}ws-001-home"
  2. s3_path = f"{cluster_id}/ws-001/op-abc123/home.tar.zst"
  3. storage-job 컨테이너: Volume → tar+zstd → S3
응답: { "exit_code": 0 }

POST /jobs/restore
요청: { "workspace_id": "ws-001", "archive_key": "cluster-id/ws-001/op-abc123/home.tar.zst" }
Agent:
  1. s3_url = archive_key로부터 S3 URL 구성
  2. volume_name = f"{prefix}ws-001-home"
  3. Volume 생성 (없으면)
  4. storage-job 컨테이너: S3 → zstd+tar → Volume
응답: { "exit_code": 0 }
```

### Storage GC API 상세

```
POST /storage/gc
요청: {
  "archive_keys": ["cluster-id/ws-001/op-aaa/home.tar.zst"],
  "protected_workspaces": [
    ["ws-001", "op-abc"],
    ["ws-002", "op-def"]
  ]
}
Agent:
  1. protected_paths 계산:
     - archive_keys에서 직접 추가
     - protected_workspaces로부터 f"{cluster_id}/ws-001/op-abc/home.tar.zst" 등 계산
  2. S3에서 {cluster_id}/ prefix로 목록 조회
  3. protected_paths에 없는 것 삭제
응답: { "deleted_count": 5 }

✅ cluster_id prefix로 다른 클러스터 archive는 건드리지 않음
```

---

## 6. Control Plane 코드 변경

### adapters/ 정리

```
현재:
src/codehub/adapters/
├── instance/      → Agent로 이동
├── volume/        → Agent로 이동
├── job/           → Agent로 이동
└── storage/       → Agent로 이동

변경 후:
src/codehub/
├── adapters/      → 삭제 또는 비움
└── agent/
    └── client.py  → AgentClient (HTTP 호출)
```

### 흐름 변경

```
현재:
  Reconciler → DockerInstanceController → Docker API

변경 후:
  Reconciler → AgentClient → Agent → Docker API
```

---

## 7. 마이그레이션 전략

```
v0.2.0 → v0.2.1:

1. 라이센스 변경 (Apache 2.0 → AGPL-3.0) ✅ 완료

2. 새 테이블 생성
   - clusters
   - cluster_members

3. workspaces 테이블 수정
   - default cluster 생성 (id: 00000000-...)
   - cluster_id 컬럼 추가 (nullable)
   - 기존 workspace에 default cluster 할당
   - cluster_id NOT NULL 제약 추가
   - instance_backend, storage_backend, home_store_key 삭제

4. 신규 workspace:
   - 클러스터 선택 필수
   - workspaces.cluster_id에 직접 저장
```

---

## 8. 마일스톤

### Phase 1: 인프라 준비

- [x] 라이센스 AGPL-3.0 변경
- [ ] clusters, cluster_members 테이블 마이그레이션
- [ ] workspaces 테이블 수정 (cluster_id 추가, deprecated 컬럼 삭제)
- [ ] Cluster 도메인 모델 및 서비스

### Phase 2: Agent 구현

- [ ] codehub_agent 패키지 생성
- [ ] Docker Runtime 구현 (기존 adapters/ 코드 이전)
- [ ] Storage GC 구현
- [ ] Agent API 엔드포인트

### Phase 3: Control Plane 리팩토링

- [ ] AgentClient 구현 (HTTP 호출)
- [ ] 기존 adapters/ 제거
- [ ] Reconciler → AgentClient 연결
- [ ] GC Scheduler → AgentClient 연결
- [ ] Cluster 등록/관리 API

### Phase 4: 통합 및 배포

- [ ] docker-compose 업데이트 (Control Plane + Agent)
- [ ] E2E 테스트
- [ ] 문서화

---

## 9. Open Questions

- [ ] Agent Health Check 주기? (제안: 30초)
- [ ] Agent 타임아웃? (제안: 30초)
- [ ] Workspace 생성 시 cluster 자동 선택 로직?

---

## References

- 현재 구현: `src/codehub/adapters/`
- 인터페이스: `src/codehub/core/interfaces/`
- 다음 버전: [v0.3.0-k8s.md](v0.3.0-k8s.md)
